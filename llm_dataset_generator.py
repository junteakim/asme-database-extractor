#!/usr/bin/env python3
"""
LLM ëª¨ë¸ í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
"""

import json
import pandas as pd
import os
from pathlib import Path
import logging
from typing import Dict, List, Any

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LLMDatasetGenerator:
    def __init__(self):
        self.datasets = {
            "training": [],
            "validation": [],
            "testing": []
        }
        self.metadata = {
            "total_samples": 0,
            "training_samples": 0,
            "validation_samples": 0,
            "testing_samples": 0,
            "categories": {}
        }
    
    def load_comprehensive_data(self):
        """ì¢…í•© ë°ì´í„° ë¡œë“œ"""
        logger.info("ğŸ“‚ ì¢…í•© ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        try:
            with open("llm_comprehensive_data.json", "r", encoding="utf-8") as f:
                data = json.load(f)
            return data
        except Exception as e:
            logger.error(f"ì¢…í•© ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def generate_material_qa_pairs(self, data):
        """ì¬ë£Œ ê´€ë ¨ Q&A ìŒ ìƒì„±"""
        logger.info("ğŸ”§ ì¬ë£Œ Q&A ìŒ ìƒì„± ì¤‘...")
        
        qa_pairs = []
        
        # ì¬ë£Œë³„ ì§ˆë¬¸ ìƒì„±
        for material_type, material_info in data.get("materials", {}).items():
            material_name = material_info.get("name", "")
            specifications = material_info.get("specifications", [])
            properties = material_info.get("properties", {})
            
            # ê¸°ë³¸ ì¬ë£Œ ì •ë³´ ì§ˆë¬¸
            qa_pairs.extend([
                {
                    "question": f"{material_name}ì˜ ì£¼ìš” ì‚¬ì–‘ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "answer": f"{material_name}ì˜ ì£¼ìš” ì‚¬ì–‘ì€ {', '.join(specifications)}ì…ë‹ˆë‹¤.",
                    "category": "material_specification",
                    "material_type": material_type
                },
                {
                    "question": f"{material_name}ì˜ ê¸°ê³„ì  íŠ¹ì„±ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "answer": f"{material_name}ì˜ ê¸°ê³„ì  íŠ¹ì„±: {json.dumps(properties, ensure_ascii=False)}",
                    "category": "mechanical_properties",
                    "material_type": material_type
                }
            ])
        
        return qa_pairs
    
    def generate_stress_qa_pairs(self, data):
        """ì‘ë ¥ê°’ ê´€ë ¨ Q&A ìŒ ìƒì„±"""
        logger.info("ğŸ”§ ì‘ë ¥ê°’ Q&A ìŒ ìƒì„± ì¤‘...")
        
        qa_pairs = []
        
        # í—ˆìš©ì‘ë ¥ê°’ ì§ˆë¬¸ ìƒì„±
        for material_type, materials in data.get("allowable_stress_values", {}).items():
            for material_name, stress_data in materials.items():
                for temp, stress_value in stress_data.items():
                    if temp != "unit":
                        qa_pairs.append({
                            "question": f"{material_name} ì¬ë£Œì˜ {temp}ì—ì„œì˜ í—ˆìš©ì‘ë ¥ê°’ì€ ì–¼ë§ˆì¸ê°€ìš”?",
                            "answer": f"{material_name} ì¬ë£Œì˜ {temp}ì—ì„œì˜ í—ˆìš©ì‘ë ¥ê°’ì€ {stress_value} {stress_data.get('unit', 'ksi')}ì…ë‹ˆë‹¤.",
                            "category": "allowable_stress",
                            "material_type": material_type,
                            "temperature": temp
                        })
        
        return qa_pairs
    
    def generate_design_qa_pairs(self, data):
        """ì„¤ê³„ ê´€ë ¨ Q&A ìŒ ìƒì„±"""
        logger.info("ğŸ”§ ì„¤ê³„ Q&A ìŒ ìƒì„± ì¤‘...")
        
        qa_pairs = []
        
        # ì„¤ê³„ ì˜ˆì‹œ ì§ˆë¬¸ ìƒì„±
        for design_type, design_info in data.get("design_examples", {}).items():
            conditions = design_info.get("conditions", {})
            materials = design_info.get("recommended_materials", [])
            conclusion = design_info.get("conclusion", "")
            
            qa_pairs.extend([
                {
                    "question": f"{design_type} ì„¤ê³„ ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "answer": f"{design_type} ì„¤ê³„ ì¡°ê±´: ì˜¨ë„ {conditions.get('temperature', 'N/A')}, ì••ë ¥ {conditions.get('pressure', 'N/A')}",
                    "category": "design_conditions",
                    "design_type": design_type
                },
                {
                    "question": f"{design_type}ì— ê¶Œì¥ë˜ëŠ” ì¬ë£ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                    "answer": f"{design_type}ì— ê¶Œì¥ë˜ëŠ” ì¬ë£Œ: {', '.join(materials)}",
                    "category": "recommended_materials",
                    "design_type": design_type
                },
                {
                    "question": f"{design_type} ì„¤ê³„ì˜ ê²°ë¡ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "answer": conclusion,
                    "category": "design_conclusion",
                    "design_type": design_type
                }
            ])
        
        return qa_pairs
    
    def generate_usage_qa_pairs(self, data):
        """ì‚¬ìš© ê°€ì´ë“œë¼ì¸ Q&A ìŒ ìƒì„±"""
        logger.info("ğŸ”§ ì‚¬ìš© ê°€ì´ë“œë¼ì¸ Q&A ìŒ ìƒì„± ì¤‘...")
        
        qa_pairs = []
        
        # ì‚¬ìš© ê°€ì´ë“œë¼ì¸ ì§ˆë¬¸ ìƒì„±
        for guideline_type, guidelines in data.get("usage_guidelines", {}).items():
            for material_type, guideline in guidelines.items():
                qa_pairs.append({
                    "question": f"{material_type}ì˜ {guideline_type}ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "answer": f"{material_type}ì˜ {guideline_type}: {guideline}",
                    "category": "usage_guideline",
                    "material_type": material_type,
                    "guideline_type": guideline_type
                })
        
        return qa_pairs
    
    def split_dataset(self, qa_pairs, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):
        """ë°ì´í„°ì…‹ ë¶„í• """
        logger.info("ğŸ“Š ë°ì´í„°ì…‹ ë¶„í•  ì¤‘...")
        
        total_samples = len(qa_pairs)
        train_size = int(total_samples * train_ratio)
        val_size = int(total_samples * val_ratio)
        
        # ì…”í”Œ
        import random
        random.shuffle(qa_pairs)
        
        self.datasets["training"] = qa_pairs[:train_size]
        self.datasets["validation"] = qa_pairs[train_size:train_size + val_size]
        self.datasets["testing"] = qa_pairs[train_size + val_size:]
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        self.metadata["total_samples"] = total_samples
        self.metadata["training_samples"] = len(self.datasets["training"])
        self.metadata["validation_samples"] = len(self.datasets["validation"])
        self.metadata["testing_samples"] = len(self.datasets["testing"])
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        categories = {}
        for qa in qa_pairs:
            cat = qa.get("category", "unknown")
            categories[cat] = categories.get(cat, 0) + 1
        
        self.metadata["categories"] = categories
        
        logger.info(f"âœ… ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ: í›ˆë ¨ {len(self.datasets['training'])}ê°œ, ê²€ì¦ {len(self.datasets['validation'])}ê°œ, í…ŒìŠ¤íŠ¸ {len(self.datasets['testing'])}ê°œ")
    
    def save_datasets(self):
        """ë°ì´í„°ì…‹ ì €ì¥"""
        logger.info("ğŸ’¾ ë°ì´í„°ì…‹ ì €ì¥ ì¤‘...")
        
        # ê° ë°ì´í„°ì…‹ ì €ì¥
        for split_name, data in self.datasets.items():
            filename = f"llm_dataset_{split_name}.json"
            with open(filename, "w", encoding="utf-8") as f:
                json.dump({
                    "metadata": {
                        "split": split_name,
                        "samples": len(data),
                        "generated_date": "2025-08-06"
                    },
                    "data": data
                }, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… {filename} ì €ì¥ ì™„ë£Œ ({len(data)}ê°œ ìƒ˜í”Œ)")
        
        # í†µí•© ë°ì´í„°ì…‹ ì €ì¥
        with open("llm_dataset_complete.json", "w", encoding="utf-8") as f:
            json.dump({
                "metadata": self.metadata,
                "datasets": self.datasets
            }, f, ensure_ascii=False, indent=2)
        
        logger.info("âœ… í†µí•© ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ")
    
    def generate_markdown_summary(self):
        """ë§ˆí¬ë‹¤ìš´ ìš”ì•½ ìƒì„±"""
        logger.info("ğŸ“ ë§ˆí¬ë‹¤ìš´ ìš”ì•½ ìƒì„± ì¤‘...")
        
        md_content = f"""# LLM í•™ìŠµìš© ë°ì´í„°ì…‹ ìš”ì•½

## ğŸ“Š ë°ì´í„°ì…‹ í†µê³„
- **ì´ ìƒ˜í”Œ ìˆ˜**: {self.metadata['total_samples']}ê°œ
- **í›ˆë ¨ ë°ì´í„°**: {self.metadata['training_samples']}ê°œ
- **ê²€ì¦ ë°ì´í„°**: {self.metadata['validation_samples']}ê°œ
- **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: {self.metadata['testing_samples']}ê°œ

## ğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
"""
        
        for category, count in self.metadata["categories"].items():
            percentage = (count / self.metadata["total_samples"]) * 100
            md_content += f"- **{category}**: {count}ê°œ ({percentage:.1f}%)\n"
        
        md_content += """
## ğŸ“ ìƒì„±ëœ íŒŒì¼
- `llm_dataset_training.json` - í›ˆë ¨ìš© ë°ì´í„°
- `llm_dataset_validation.json` - ê²€ì¦ìš© ë°ì´í„°
- `llm_dataset_testing.json` - í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°
- `llm_dataset_complete.json` - í†µí•© ë°ì´í„°ì…‹

## ğŸ¯ ì‚¬ìš© ë°©ë²•
1. í›ˆë ¨ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ
2. ê²€ì¦ ë°ì´í„°ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
3. í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì¢… ì„±ëŠ¥ í‰ê°€

## ğŸ“‹ ìƒ˜í”Œ ë°ì´í„° í˜•ì‹
```json
{
  "question": "SA-516 Grade 70 ì¬ë£Œì˜ 400Â°Fì—ì„œì˜ í—ˆìš©ì‘ë ¥ê°’ì€ ì–¼ë§ˆì¸ê°€ìš”?",
  "answer": "SA-516 Grade 70 ì¬ë£Œì˜ 400Â°Fì—ì„œì˜ í—ˆìš©ì‘ë ¥ê°’ì€ 18.5 ksiì…ë‹ˆë‹¤.",
  "category": "allowable_stress",
  "material_type": "carbon_steel",
  "temperature": "400F"
}
```
"""
        
        with open("llm_dataset_summary.md", "w", encoding="utf-8") as f:
            f.write(md_content)
        
        logger.info("âœ… ë§ˆí¬ë‹¤ìš´ ìš”ì•½ ìƒì„± ì™„ë£Œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ LLM ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘...")
    
    generator = LLMDatasetGenerator()
    
    # ì¢…í•© ë°ì´í„° ë¡œë“œ
    data = generator.load_comprehensive_data()
    if not data:
        logger.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # Q&A ìŒ ìƒì„±
    all_qa_pairs = []
    all_qa_pairs.extend(generator.generate_material_qa_pairs(data))
    all_qa_pairs.extend(generator.generate_stress_qa_pairs(data))
    all_qa_pairs.extend(generator.generate_design_qa_pairs(data))
    all_qa_pairs.extend(generator.generate_usage_qa_pairs(data))
    
    logger.info(f"âœ… ì´ {len(all_qa_pairs)}ê°œì˜ Q&A ìŒ ìƒì„± ì™„ë£Œ")
    
    # ë°ì´í„°ì…‹ ë¶„í• 
    generator.split_dataset(all_qa_pairs)
    
    # ë°ì´í„°ì…‹ ì €ì¥
    generator.save_datasets()
    
    # ìš”ì•½ ìƒì„±
    generator.generate_markdown_summary()
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ:")
    print(f"ì´ Q&A ìŒ: {generator.metadata['total_samples']}ê°œ")
    print(f"í›ˆë ¨ ë°ì´í„°: {generator.metadata['training_samples']}ê°œ")
    print(f"ê²€ì¦ ë°ì´í„°: {generator.metadata['validation_samples']}ê°œ")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {generator.metadata['testing_samples']}ê°œ")
    
    logger.info("ğŸ‰ LLM ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    main() 