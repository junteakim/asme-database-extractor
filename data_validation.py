#!/usr/bin/env python3
"""
ASME BPVC ë°ì´í„° ê²€ì¦ ë° í’ˆì§ˆ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
"""

import json
import pandas as pd
import os
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ASMEDataValidator:
    def __init__(self, data_dir="output"):
        self.data_dir = Path(data_dir)
        self.validation_results = {
            "total_files": 0,
            "valid_files": 0,
            "invalid_files": 0,
            "errors": [],
            "warnings": [],
            "statistics": {}
        }
    
    def validate_csv_files(self):
        """CSV íŒŒì¼ë“¤ì˜ ìœ íš¨ì„± ê²€ì¦"""
        logger.info("ğŸ” CSV íŒŒì¼ ê²€ì¦ ì‹œì‘...")
        
        csv_files = list(self.data_dir.glob("Page_*_Table_*.csv"))
        self.validation_results["total_files"] += len(csv_files)
        
        for csv_file in csv_files:
            try:
                # CSV íŒŒì¼ ì½ê¸°
                df = pd.read_csv(csv_file)
                
                # ê¸°ë³¸ ê²€ì¦
                if df.empty:
                    self.validation_results["errors"].append(f"{csv_file.name}: ë¹ˆ íŒŒì¼")
                    self.validation_results["invalid_files"] += 1
                    continue
                
                # ë°ì´í„° íƒ€ì… ê²€ì¦
                if not self._validate_data_types(df):
                    self.validation_results["warnings"].append(f"{csv_file.name}: ë°ì´í„° íƒ€ì… ë¬¸ì œ")
                
                # ê²°ì¸¡ê°’ ê²€ì¦
                missing_count = df.isnull().sum().sum()
                if missing_count > 0:
                    self.validation_results["warnings"].append(f"{csv_file.name}: {missing_count}ê°œ ê²°ì¸¡ê°’")
                
                self.validation_results["valid_files"] += 1
                
            except Exception as e:
                self.validation_results["errors"].append(f"{csv_file.name}: {str(e)}")
                self.validation_results["invalid_files"] += 1
        
        logger.info(f"âœ… CSV ê²€ì¦ ì™„ë£Œ: {len(csv_files)}ê°œ íŒŒì¼")
    
    def validate_json_files(self):
        """JSON íŒŒì¼ë“¤ì˜ ìœ íš¨ì„± ê²€ì¦"""
        logger.info("ğŸ” JSON íŒŒì¼ ê²€ì¦ ì‹œì‘...")
        
        json_files = list(self.data_dir.glob("Page_*_Chart_*.json"))
        self.validation_results["total_files"] += len(json_files)
        
        for json_file in json_files:
            try:
                # JSON íŒŒì¼ ì½ê¸°
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # JSON êµ¬ì¡° ê²€ì¦
                if not isinstance(data, dict):
                    self.validation_results["errors"].append(f"{json_file.name}: ì˜ëª»ëœ JSON êµ¬ì¡°")
                    self.validation_results["invalid_files"] += 1
                    continue
                
                self.validation_results["valid_files"] += 1
                
            except json.JSONDecodeError as e:
                self.validation_results["errors"].append(f"{json_file.name}: JSON íŒŒì‹± ì˜¤ë¥˜ - {str(e)}")
                self.validation_results["invalid_files"] += 1
            except Exception as e:
                self.validation_results["errors"].append(f"{json_file.name}: {str(e)}")
                self.validation_results["invalid_files"] += 1
        
        logger.info(f"âœ… JSON ê²€ì¦ ì™„ë£Œ: {len(json_files)}ê°œ íŒŒì¼")
    
    def validate_llm_data_files(self):
        """LLM ë°ì´í„° íŒŒì¼ë“¤ì˜ ìœ íš¨ì„± ê²€ì¦"""
        logger.info("ğŸ” LLM ë°ì´í„° íŒŒì¼ ê²€ì¦ ì‹œì‘...")
        
        llm_files = [
            "llm_comprehensive_data.json",
            "llm_raw_data.json", 
            "llm_massive_data.json",
            "llm_actual_data.json",
            "llm_ready_data.json"
        ]
        
        for llm_file in llm_files:
            if not os.path.exists(llm_file):
                self.validation_results["errors"].append(f"{llm_file}: íŒŒì¼ ì—†ìŒ")
                continue
            
            try:
                with open(llm_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # íŒŒì¼ í¬ê¸° í™•ì¸
                file_size = os.path.getsize(llm_file)
                self.validation_results["statistics"][llm_file] = {
                    "size_kb": file_size / 1024,
                    "structure_valid": isinstance(data, dict)
                }
                
                logger.info(f"âœ… {llm_file}: {file_size/1024:.1f}KB")
                
            except Exception as e:
                self.validation_results["errors"].append(f"{llm_file}: {str(e)}")
    
    def _validate_data_types(self, df):
        """ë°ì´í„° íƒ€ì… ê²€ì¦"""
        # ìˆ«ì ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        numeric_columns = df.select_dtypes(include=['number']).columns
        return len(numeric_columns) > 0
    
    def generate_validation_report(self):
        """ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ğŸ“Š ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        report = {
            "validation_summary": {
                "total_files_checked": self.validation_results["total_files"],
                "valid_files": self.validation_results["valid_files"],
                "invalid_files": self.validation_results["invalid_files"],
                "success_rate": f"{(self.validation_results['valid_files'] / self.validation_results['total_files'] * 100):.1f}%" if self.validation_results["total_files"] > 0 else "0%"
            },
            "errors": self.validation_results["errors"],
            "warnings": self.validation_results["warnings"],
            "statistics": self.validation_results["statistics"],
            "recommendations": self._generate_recommendations()
        }
        
        # JSON ë¦¬í¬íŠ¸ ì €ì¥
        with open("validation_report.json", "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
        self._generate_markdown_report(report)
        
        logger.info("âœ… ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        return report
    
    def _generate_recommendations(self):
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if self.validation_results["invalid_files"] > 0:
            recommendations.append("âŒ ì˜¤ë¥˜ê°€ ìˆëŠ” íŒŒì¼ë“¤ì„ ìˆ˜ì •í•˜ì„¸ìš”")
        
        if len(self.validation_results["warnings"]) > 0:
            recommendations.append("âš ï¸ ê²½ê³ ì‚¬í•­ë“¤ì„ ê²€í† í•˜ê³  ê°œì„ í•˜ì„¸ìš”")
        
        if self.validation_results["valid_files"] / self.validation_results["total_files"] < 0.95:
            recommendations.append("ğŸ“ˆ ë°ì´í„° í’ˆì§ˆì„ ê°œì„ í•˜ì„¸ìš”")
        
        if not recommendations:
            recommendations.append("âœ… ëª¨ë“  ë°ì´í„°ê°€ ì •ìƒì ìœ¼ë¡œ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        return recommendations
    
    def _generate_markdown_report(self, report):
        """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
        md_content = f"""# ASME BPVC ë°ì´í„° ê²€ì¦ ë¦¬í¬íŠ¸

## ğŸ“Š ê²€ì¦ ìš”ì•½
- **ì´ ê²€ì¦ íŒŒì¼ ìˆ˜**: {report['validation_summary']['total_files_checked']}ê°œ
- **ìœ íš¨í•œ íŒŒì¼ ìˆ˜**: {report['validation_summary']['valid_files']}ê°œ
- **ì˜¤ë¥˜ íŒŒì¼ ìˆ˜**: {report['validation_summary']['invalid_files']}ê°œ
- **ì„±ê³µë¥ **: {report['validation_summary']['success_rate']}

## ğŸ“ LLM ë°ì´í„° íŒŒì¼ í†µê³„
"""
        
        for file_name, stats in report['statistics'].items():
            md_content += f"- **{file_name}**: {stats['size_kb']:.1f}KB\n"
        
        if report['errors']:
            md_content += "\n## âŒ ì˜¤ë¥˜ ëª©ë¡\n"
            for error in report['errors']:
                md_content += f"- {error}\n"
        
        if report['warnings']:
            md_content += "\n## âš ï¸ ê²½ê³  ëª©ë¡\n"
            for warning in report['warnings']:
                md_content += f"- {warning}\n"
        
        md_content += "\n## ğŸ’¡ ê¶Œì¥ì‚¬í•­\n"
        for rec in report['recommendations']:
            md_content += f"- {rec}\n"
        
        with open("validation_report.md", "w", encoding="utf-8") as f:
            f.write(md_content)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ ASME BPVC ë°ì´í„° ê²€ì¦ ì‹œì‘...")
    
    validator = ASMEDataValidator()
    
    # ê°ì¢… ê²€ì¦ ì‹¤í–‰
    validator.validate_csv_files()
    validator.validate_json_files()
    validator.validate_llm_data_files()
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    report = validator.generate_validation_report()
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼:")
    print(f"ì´ íŒŒì¼ ìˆ˜: {report['validation_summary']['total_files_checked']}")
    print(f"ì„±ê³µë¥ : {report['validation_summary']['success_rate']}")
    print(f"ì˜¤ë¥˜ ìˆ˜: {len(report['errors'])}")
    print(f"ê²½ê³  ìˆ˜: {len(report['warnings'])}")
    
    logger.info("ğŸ‰ ë°ì´í„° ê²€ì¦ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 